-- this library contains all functions needed to set up a standard Subtree structure for an Asset
--
-- Part of Predictive Maintenance Library
--
-- Authors: JaegerMK, marco-klaus.jaeger@basf.com
--          SauerS11, simeon.sauer@basf.com
--          MorenoF5, fernado.moreno-leira@basf.com
-- Version 0.5
-- 20170421 copyLimits added
-- 20170614 back-calculate history added 
-- 20170711 added alarming function
-- TODO: use new esi libs, schema check, config encapsulation in tables, write in ESI standard

local setUp = {}

-- create folder structure for generic asset model
setUp.create_folders = function(cwd, additional_folders)
	local out = 0
	local objLib = require "inmation.Objects"

	objLib.ensureFolder(cwd,"_Inputs","Holds all Input Tags")

	objLib.ensureFolder(cwd,"_Calculations","Calculated Values and Calculation Scripts")

	local dbgpath = objLib.ensureFolder(cwd,"_Debug","Debugging")
	objLib.ensureHolder(dbgpath,"_DBG","Created for debugging")

	objLib.ensureFolder(cwd,"_Filtered","")

	objLib.ensureFolder(cwd,"_Intermediates","Holds the Alias Input Values")


	if (additional_folders ~= nil) then
	-- create additional folders
		for _,foldername in pairs(additional_folders) do
		objLib.ensureFolder(cwd,foldername,"")
		end
	end

	return "folders created"

end

-- this function creates data holding objects in the inputs folder, to store the values(and quality), of the inputs defined in t
-- it also generates the customized script that will be placed in the same folder, that performs the copy. Creates the triggering 
-- links as well

function setUp.define_deploy_inputs(plantpath,cwd,t)
  
    local objLib = require "inmation.Objects"
	local inputspath = cwd.."/_Inputs"
    	
	local references_table = {}
	
	-- metacoding, writting the script to perform the value transfer for the required signals
	local transfer_script = "--script automatically generated by define_deploy_inputs.lua \n"..
							"local setUp = require \"PredM.setUp\" \n" ..
							"local plantpath = \""..plantpath.."\"\n"..
							"local cwd       = \""..cwd.."\"\n"..
							"local t = setUp.readtable(cwd)\n"
							
							
	for i in pairs(t) do
	
		local alias = t[i].alias
		local tag   = t[i].tag
		local minlim = t[i].minlim
		local maxlim = t[i].maxlim
		local engunits = t[i].eu
		local subfolder_name = t[i].subfolder
		local buffer = t[i].buffer
		
		-- use alternative plantpath if present in t
		if nil~= t[i].source then
			references_table[i] = {name = tag ,path =t[i].source.."/"..tag}
		else
			-- adding all the inputs as "triggering" references
			references_table[i] = {name = tag ,path =plantpath.."/"..tag}
		end
			
		-- check if DataHolder should be in a Subfolder
		local current_path = inputspath
		if subfolder_name ~= nil then
			current_path = current_path .. "/" .. subfolder_name
			objLib.ensureFolder(inputspath,subfolder_name,"")
		end
			

		-- get pointer to the object storing the individual tag information
		local opath,obj = objLib.ensureHolder(current_path,tag,"alias "..alias,nil,nil,nil,nil,nil,engunits,nil,true)
		
		-- set both EU Range AND Limits to the specified min/max limits
    if minlim then
      obj.Limits.OpcLimitLow = minlim
      obj.Limits.OpcRangeLow = minlim
    end
    if maxlim then
      obj.Limits.OpcLimitHigh = maxlim
      obj.Limits.OpcRangeHigh = maxlim
    end
  
		obj:commit()

	end

	transfer_script = transfer_script .. "return setUp.connect_inputs(plantpath,cwd,t)\n"

	-- creation of the object that will exectute the transfer script
	local _,obj = objLib.ensureAction(inputspath,"_read_inputs","", nil,nil,nil,nil,true,transfer_script)
	inmation.setreferences(obj,references_table)

	return "mapping done"
end

function setUp.connect_inputs(plantpath,cwd,t)
-- this function copies the value from the tags plantpath/t[i][2] into the cwd/Inputs/t[i][2] data holder
	local inputspath = cwd.."/_Inputs"
	local tempx = 0
	local tempq = 0
	local tempy = 0
	
	
	for i in pairs(t) do
	
		local alias = t[i].alias
		local tag   = t[i].tag
		local minlim = t[i].minlim
		local maxlim = t[i].maxlim
		local subfolder_name = t[i].subfolder
		local altsource = t[i].source
		
		local current_path = inputspath
		if subfolder_name ~= nil then
			current_path = current_path .. "/" .. subfolder_name
		end
		
		-- read value and quality and timestamp from plantpath
		if nil == altsource then
			tempx,tempq,tempy= inmation.getvalue(plantpath .."/".. tag)
		else
			tempx,tempq,tempy= inmation.getvalue(altsource .."/".. tag)
		end
		
		-- check if the value is a visitor from the future
    
   		local cTime = inmation.now()
    	if tempy > cTime+(30*1000) then  --(+30 seconds, because short term future Timestamps are ok. only prevent long term future Timestamps, which are a problem for buffering)
    		  tempy = cTime
   		end
		-- writing value and quality and timestamp to cwd/Inputs
		inmation.set(current_path .."/".. tag,tempx,tempq,tempy)
	end
	
	if g_trigger == nil then g_trigger = 0 	end
 	if g_trigger == 0 then
		g_trigger = 1
 	else
		g_trigger = 0
 	end
 	
 	return g_trigger
	
end

function setUp.match_standard_inputs(cwd,from_f,to_f,t)
  
  local objLib = require "inmation.Objects"
	local topath = cwd.."/"..to_f
	local plantpath = cwd.."/"..from_f
	
	local references_table = {}
	local transfer_script = "--script automatically generated by match_standard_inputs.lua \n"..
							"local setUp = require \"PredM.setUp\" \n" ..
							"local plantpath = \""..plantpath.."\"\n"..
							"local cwd       = \""..cwd.."\"\n"..
							"local t = setUp.readtable(cwd)\n"
							
							
	for i in pairs(t) do
	
		local alias = t[i].alias
		local tag   = t[i].tag
		local minlim = t[i].minlim
		local maxlim = t[i].maxlim
		local engunits = t[i].eu
		local subfolder_name = t[i].subfolder
		local buffer = t[i].buffer
    local MA = t[i].MA
		
		local current_path = topath
		-- check if DataHolder should be in a Subfolder
    	if subfolder_name ~= nil then
			current_path = current_path .. "/" .. subfolder_name
			references_table[i] = {name = tag ,path =plantpath.."/" .. subfolder_name .. "/" ..tag}
			-- check if subfolder is already existing
      		objLib.ensureFolder(topath,subfolder_name,"")
			
			else
			references_table[i] = {name = tag ,path =plantpath.."/"..tag}
			
		end
		
		local opath,obj = objLib.ensureHolder(current_path,alias,alias .. " from " .. tag,nil,nil,nil,nil,nil,engunits,nil,true)
		
    if minlim then
      obj.Limits.OpcLimitLow = minlim
      obj.Limits.OpcRangeLow = minlim
    end
    if maxlim then
      obj.Limits.OpcLimitHigh = maxlim
      obj.Limits.OpcRangeHigh = maxlim
    end
    
		obj:commit()
    
    if buffer ~= nil and type(buffer) == "number" then
      if MA then
        local duration = buffer
        local size = buffer/100  -- expected size is duration of aggregation in seconds or less
        inmation.buffer(obj, "RawBuffer", ".ItemValue", duration, size)
        local Agg_duration = buffer*2
        inmation.buffer(obj, "AvgBuffer", "RawBuffer", Agg_duration, 10, 0, "AGG_TYPE_AVERAGE")
      else
        local duration = buffer*3
        local size = buffer/1000  -- expected size is duration of aggregation in seconds or less
        inmation.buffer(obj, "RawBuffer", ".ItemValue", duration, size)
        local Agg_duration = buffer*5
        inmation.buffer(obj, "AvgBuffer", "RawBuffer", Agg_duration, 10, buffer, "AGG_TYPE_AVERAGE")
      end
	end

	end
	transfer_script = transfer_script .. "return setUp.connect_intermediates(plantpath,cwd,t)\n"
	
	opath,obj = objLib.ensureAction(topath,"read_aliases","",nil,nil,nil,nil,true,transfer_script)
	inmation.setreferences(obj,references_table)

	return "inputs 2 aliases mapping done"
end

function setUp.connect_intermediates(plantpath,cwd,t)

	local inputspath = cwd.."/_Intermediates"
	local tempx = 0
	local tempq = 0
	local tempy = 0
	
	
	for i in pairs(t) do
	
		local alias = t[i].alias
		local tag   = t[i].tag
		local minlim = t[i].maxlim
		local maxlim = t[i].minlim
		local subfolder_name = t[i].subfolder
		local buffer = t[i].buffer
		
		local relpath = "/"
		
		if subfolder_name ~= nil then
			relpath = "/" .. subfolder_name .. "/"
		end
		
			local tempx,tempq,tempy= inmation.getvalue(plantpath .. relpath .. tag)
			inmation.set(inputspath.. relpath .. alias,tempx,tempq,tempy)
	end
	
	if g_trigger == nil then g_trigger = 0 	end
 	if g_trigger == 0 then
		g_trigger = 1
 	else
		g_trigger = 0
 	end
 	
 	return g_trigger
	
end

function setUp.create_filtered(cwd,t)
    
  local objLib = require "inmation.Objects"
	local topath = cwd.."/_Filtered"
	local plantpath = cwd.."/_Intermediates"
	
	local references_table = {}
	local transfer_script = "--script automatically generated by setUp.create_filtered \n"..
							"local setUp = require \"PredM.setUp\" \n" ..
							"local plantpath = \""..plantpath.."\"\n"..
							"local cwd       = \""..cwd.."\"\n"..
							"local t = setUp.readtable(cwd)\n"
							
							
	for i in pairs(t) do
	
		local alias = t[i].alias
		local tag   = t[i].tag
		local minlim = t[i].minlim
		local maxlim = t[i].maxlim
		local engunits = t[i].eu
		local subfolder_name = t[i].subfolder
		local buffer = t[i].buffer
		
		local current_path = topath
		-- check if DataHolder should be in a Subfolder
    	if subfolder_name ~= nil then
			current_path = current_path .. "/" .. subfolder_name
			references_table[i] = {name = alias ,path =plantpath.."/" .. subfolder_name .. "/" ..alias}
			-- check if subfolder is already existing
      		objLib.ensureFolder(topath,subfolder_name,"")
			
			else
			references_table[i] = {name = alias ,path =plantpath.."/"..alias}
			
		end
		
	if buffer and type(buffer) == "number" then -- only create Filtered Holder, if value should be filtered
		local opath,obj = objLib.ensureHolder(current_path,alias,tag .. " ( " .. (buffer/60000) .. " minutes average)" ,nil,nil,nil,nil,nil,engunits,nil,true)
		
		obj.Limits.OpcLimitLow = minlim
		obj.Limits.OpcLimitHigh = maxlim
		obj.Limits.OpcRangeLow = minlim
		obj.Limits.OpcRangeHigh = maxlim
		obj:commit()
    end

	end
	transfer_script = transfer_script .. "return setUp.connect_filtered(plantpath,cwd,t)\n"
	
	opath,obj = objLib.ensureAction(topath,"read_buffers","",nil,nil,nil,nil,true,transfer_script)
  inmation.setreferences(obj,references_table)

	return  
  
end

function setUp.connect_filtered(plantpath,cwd,t)
  local inputspath = cwd.."/_Filtered"
	local tempx = 0
	local tempq = 0
	local tempy = 0
	
	
	for i in pairs(t) do
	
		local alias = t[i].alias
		local tag   = t[i].tag
		local minlim = t[i].maxlim
		local maxlim = t[i].minlim
		local subfolder_name = t[i].subfolder
		local buffer = t[i].buffer
		local MA = t[i].MA 
		
		local relpath = "/"
		
		if subfolder_name ~= nil then
			relpath = "/" .. subfolder_name .. "/"
		end
		
		if buffer ~= nil and type(buffer) == "number" then
			
			local tempx, tempq, tempy, count = inmation.peek(plantpath .. relpath ..alias, "AvgBuffer")
			
      if #tempy == 0 then -- buffer is empty (e.g., because it has just been instantiated), no values available yet; take the current value instead
				local tempx2, tempq2, tempy2 = inmation.getvalue(plantpath .. relpath ..alias)
				inmation.set(inputspath.. relpath .. alias,tempx2,tempq2,tempy2)
			else
				if MA then
					inmation.set(inputspath.. relpath .. alias,tempx[#tempy],tempq[#tempy],tempy[#tempy])
				else
					inmation.set(inputspath..relpath..alias, tempx[#tempy]) -- if it's not a moving average buffer, set the timestamp to when the value changed, not the beginning of the aggregated window
				end
			end
    elseif type(inmation.getobject(inputspath.. relpath .. alias)) == "table" then
      local v = inmation.get(plantpath.. relpath .. alias)
      inmation.set(inputspath .. relpath .. alias,v)
		end
    
    
	end
  
  return true
	
end

function setUp.storetable(cwd,t,dataholdername)
-- stores a given t table as json string in the data holder's value field. 
-- by default, if dataholdername is empty, then an object t_holder will be created
	local json = require "inmation.json"
  local objLib = require 'inmation.Objects'
	local t_json = json:encode(t)
	if dataholdername == nil then 
		objLib.ensureHolder(cwd,"t_holder","this data holder stores a json version of the input table t",t_json, nil, true)
		return "table stored to t_holder "
	elseif type(dataholdername) == "string" then
		objLib.ensureHolder(cwd,dataholdername,"this data holder stores a json version of the input table t",t_json, nil, true)
		return "table stored to " ..dataholdername .. " "
	else
		-- non valid name for data holder
		return "invalid name "
	end

end

function setUp.readtable(cwd,dataholdername)
-- read a given json string from the data holder's value field, and transforms it back to table
-- by default, if dataholdername is empty, object t_holder will be read
	local json = require "inmation.json"
  local objLib = require 'inmation.Objects'
	local t
	if dataholdername == nil then 
		t = json:decode(inmation.getvalue(cwd .. "/".."t_holder"))
		return t
	elseif objLib.isholderobject(inmation.getobject(cwd .. "/"..dataholdername)) then
		t = json:decode(inmation.getvalue(cwd .. "/".. dataholdername))
		return t
	else
		-- non existing data holder
		return {}
	end
end

function setUp.match_userdefined_inputs(cwd,from_f,to_f,input_calculations,script_header,var_list)
-- this function adds structures to accomodate non-standard inputs or calculations
-- will define data holder items for the new resulting calculations, in folder to_f
-- will generate code to continuously update the value of this new item, reading from folder from_f
-- the calculations will be read from the table input_calculations, with format
-- Important(!): if calculations are build on each other (e.g. first calc Fc = Fc1+Fc2, second F_mean = Fc/2) give these calculations in the right order!
	-- {name_of_calculation, calculation based on the input variables}
	-- eg. {Fh,Fh1 + Fh2/1000 - Fh3} --> Fh = Fh1 + Fh2/1000 - Fh3
	--local mlib = require "inmation.deploy_transfer_object"
	--local mlib = require "inmation.deploy_calculation_holder"

	local topath = cwd.."/"..to_f
	local frompath = cwd.."/"..from_f
	local temp = 0
	
	local references_table = {}
	local transfer_script = ""
							
	if not (script_header == nil) then
		transfer_script = transfer_script .. script_header
	end
							
	local tag = ""
	
	local avail_inputs = inmation.findobjects(frompath.."/",1,false,true)
	local avail_outputs = inmation.findobjects(topath.."/",1,false,true)
	
	local temp_str = ""
	local localstr = ""
	local assigntotablestr = ""
	local required_inputs = ""
	
	--inmation.setvalue("/System/Core/Connector/Fernando/template_W201/Debug/DBG",temp_str)
	--	inmation.setvalue("/System/Core/Connector/Fernando/template_W201/Debug/DBG",0)
	local n = 0
	
  transfer_script = transfer_script.."local t_temp_time = {}\n local temp_time\n"
  for j,v in pairs(avail_inputs) do
    if v.ObjectName ~= "read_aliases" and v.ObjectName ~= "read_custom_aliases" and v.ObjectName ~= "read_buffers" and (v.ObjectDescription ~= "" or to_f == "_Calculations") then -- checking description to identify calculated values. 
      table.insert(references_table,{name = v.ObjectName,path = frompath.."/"..v.ObjectName})
      temp_str = ""..v.ObjectName..",_,temp_time".. "= inmation.get(\""..v.ObjectName.."\")"
      assigntotablestr = "\n table.insert(t_temp_time,temp_time)\n"
      transfer_script = transfer_script..temp_str..assigntotablestr.."\n"
      localstr = localstr.."local "..v.ObjectName.." = nil\n"
    end
    
  end
  
  transfer_script = transfer_script .."table.sort(t_temp_time)\nlocal out_time =  t_temp_time[#t_temp_time] \nif out_time > inmation.now() then\n out_time = inmation.now()\nend\n"
  
  
	for i in pairs(input_calculations) do
		local output_name = input_calculations[i].alias
    local output_eu = input_calculations[i].eu
		local inputformula = input_calculations[i].formula
		local niltest = ""
		transfer_script = transfer_script.."--deploying calculation "..output_name.."="..inputformula.."\n"
		
		for j,v in pairs(avail_inputs) do -- cicle through all available inputs
      -- if the input is part of the used formula and not the output name, add to references, get the value and add to niltest (not nil, for following arithmetic operation)
			if (string.find(inputformula,v.ObjectName,1,true) and v.ObjectName ~= output_name) then
				niltest = niltest .. v.ObjectName .." == nil or "
      end
		end
	
		local passive_ref = setUp.deploy_calculation_holder(topath,output_name,output_eu)
	
		-- not certain if the next part is needed? --JaegerMK
		if not (var_list == nil) then
			for j=1,#var_list do
				local required_varname = var_list[j] 
						
				if  (not(string.find(inputformula,required_varname,1,true) == nil) and (string.find(niltest,required_varname,1,true) == nil )) then
					niltest = niltest..required_varname.." == nil or "
				end
				
			end
		end
    
    
    -- this part is for scaling the KPIs to a 0 - 100 range
    local scaling = ")"
    
    -- check if the current calculation is used as a KPI in VKPI, and set a scaling factor so it will be 
    for i,val in pairs(VKPI) do
      if output_name == val.objname then
        scaling = "- " .. val.min .. ")/(" .. val.max - val.min .. "/100)"
      end
    end
    		
		transfer_script = transfer_script .. "if not("..niltest.."false) then\n"
		transfer_script = transfer_script ..""..output_name.." = (("..inputformula..")"..scaling .. "\n"
		
		transfer_script = transfer_script.."inmation.set(\""..output_name.."\","..output_name..",0,out_time)\n" 
		transfer_script = transfer_script .."end\n"
		transfer_script = transfer_script .."\n"
		table.insert(references_table,passive_ref)
	end
	
	transfer_script = transfer_script .. "if g_trigger == nil then g_trigger = 0 	end \n"..
 										" if g_trigger == 0 then g_trigger = 1 else g_trigger = 0 end\n"..
 										" return g_trigger\n"

										
	if not (var_list == nil) then
		for j=1,#var_list do
			local required_varname = var_list[j] 
			local required_var_str = "local "..required_varname.." = nil\n"
			
			if  (string.find(localstr,required_var_str,1,true) == nil) then
				localstr = localstr .. required_var_str
			end
		end
	
		localstr = localstr .. required_inputs
	end
	
	transfer_script = "--script automatically generated by match_userdefined_inputs.lua \n"..
							"local mlib = require \"PredM.setUp\"\n"..
							"\n" ..
							localstr .. "\n"..
							transfer_script 
										
	setUp.deploy_transfer_object(topath,"read_custom_aliases",references_table,transfer_script)
	
	return n
end

function setUp.deploy_transfer_object(topath,objname,references_table,transfer_script)
-- creates or modifies an action item that will contain references (table) and some lua code
	local objLib = require "inmation.Objects"
  local objpath,obj = objLib.ensureAction(topath, objname, "", nil, nil, nil, nil, true, transfer_script)
  obj.refs = references_table
  obj:commit()
end

function setUp.deploy_calculation_holder(topath,objname,eu)
-- creates a holder item with name objname, and returns a passive reference table
	local objLib = require "inmation.Objects"
  local objpath = objLib.ensureHolder(topath, objname,"", nil,nil,nil,nil,nil,eu,nil,true)
	
	return {name=objname,path=objpath ,type="OBJECT_LINK_PASSIVE"}
end

function setUp.off_conditions(cwd,from_f,to_f,t,VKPI)
-- generates an additional calculation data holder, which is 1 when the plant is 
-- in operation, and 0 when it is offline
-- t table will be scanned for rows with off_condition != nil, and implement that test
-- if more than one row contains such a condition, an OR logical test will be done.
-- more advanced off conditions can be defined in the input_calculations with the name(s) "adv_off_condition" (add numbers for more conditions "adv_off_condition1", etc
	local json = require "inmation.json"
    local objLib = require "inmation.Objects"
	local t_off_conditions = {}
  local t_references = {}
  	-- initialize script, that watches the off_conditions
	local func_script = [[--automatically generated by setUp.off_conditions 
		local setUp = require "PredM.setUp" 
		local t_off = false]]
	
  -- search for simple off conditions in t and evaluate if there are any
  for i,val in pairs(t) do
    if val.off_condition ~= nil and type(val.off_condition) == "string"  then
      table.insert(t_off_conditions, val.alias .. val.off_condition)
      table.insert(t_references, {name = val.alias, path = cwd.."/_Intermediates/"..val.alias})
    end
  end
  
  -- get advanced off_conditions: check all elements of Intermediates Folder for "adv_off_condition" 
  local folder = inmation.getobject(cwd.."/_Intermediates")
  local cdren = folder:children()
  
  for _,val in pairs(cdren) do
    if string.find(val.ObjectName, "adv_off_condition") then
      table.insert(t_off_conditions, val.ObjectName)
      table.insert(t_references, {name = val.ObjectName, path = val:path()})
    end
  end
  
  -- get all referenced values
  for i,val in pairs(t_references) do
    func_script = func_script .. "\nlocal " .. val.name .. " = inmation.get(\"" .. val.name .. "\")"
  end
  
  func_script = func_script .. "\nt_off = t_off"
  
  for i,val in pairs(t_off_conditions) do
    func_script = func_script .. " or " .. val
  end
  
  local current_script = func_script .. "\nif t_off then return -3 \nelse return 103 \nend"
  --create the Item watching the condition
  local _,obj = objLib.ensureAction(cwd .. "/_Calculations","in_Operation","This script shows if the equipment ist currently in operation", nil,nil,nil,nil,true,current_script)
  inmation.setreferences(obj,t_references)
  
	
		if #t_off_conditions > 0 then
			return "one or more off_conditions found " .. json:encode(t_off_conditions)
		else
			return "no off_conditions present"
	end
end

function setUp.copyLimits(fromObj,toObj)
-- This copyLimits function can be used to copy all possible Limit Properties of one object to another
-- obj or path are accepted as input  
  -- check if the input are objects and transform to path if necessary
  if (type(fromObj) == "table") then
    fromObj = fromObj:path()
  end
  
  if (type(toObj) == "table") then
    toObj = toObj:path()
  end
  
  -- These properties hold Limit values, which should be copied to another object
  local Limits_propnames = {".Limits.OpcLimitLow",".Limits.OpcLimitHigh",".Limits.OpcRangeLow",".Limits.OpcRangeHigh"}
  
  for i,v in pairs(Limits_propnames) do 
    local limit = get(fromObj .. v)
    set(toObj .. v, limit)
  end
  
end

function setUp.fill_history(cwd,path_historical_data,t_start_backcalc,t_end_backcalc,sampletime)
-- This function reads historical data for the inputs to the currrent asset, stops the 
-- action item connecting the inputs with the data holder, and writes the historical values
-- sequentially to the inputs data holder. this starts a cascade, that will perform all alias assignements, 
-- the calculation of inputs and kpis, and will finally restart the action item.
-- INPUTS: cwd, path_historical_data: as usual
-- 		   t_start_backcalc, t_end_backcalc -> Format: 2016.12.20 00:00:00
-- 		   sampletime: in minutes
-- IMPORTANT: Do not import too many data at once! split longer history in parts and run the script multiple times.
-- depending on the sampletime split the timespan. (e.g. 360minutes sampletime and 1 year of history works fine, runtime: ~30 seconds) (JaegerMK 20170620)

	local essLib = require'inmation.Essentials'
	local env = essLib.Env
	local objLib = require'inmation.Objects'

	local function init()

		inmation.disableobject(cwd.."/_Inputs/_read_inputs")

		-- if not defined, path_historical_data = cwd/_Inputs
		if nil == path_historical_data then
			path_historical_data = cwd.."/_Inputs"
		end
		-- if not defined, backcalculate up to the current time
		if nil == t_end_backcalc then
			t_end_backcalc = inmation.gettime(inmation.now(),"%Y.%m.%d %H:%M:%S")
		end
		-- if not defined, backcalculate period is one year
		if nil == t_start_backcalc then
			t_start_backcalc = inmation.gettime(t_end_backcalc,"%Y.%m.%d %H:%M:%S") - 365*24*60*60*1000
		end
		-- if not defined, sampletime set to one hour
		if nil == sampletime then
			sampletime = 60 -- minutes
		end

		local plant_path = path_historical_data

		local variables = {}
		local variables_path ={}

		-- read the variables to import from the json table t
		local t = setUp.readtable(cwd)
    
        --clear all buffers before importing historic data
    for i,v in pairs(t) do
      inmation.tear(cwd.."/_Intermediates/"..v.alias,"RawBuffer")
      inmation.tear(cwd.."/_Intermediates/"..v.alias,"AvgBuffer")
    end
    
		for i=1,#t do
			if t[i].type == "inputs" then
				table.insert(variables,t[i].tag)
			end
		end
		-- compile variable paths to read historical data
		for i = 1,#variables do
			table.insert(variables_path,plant_path .."/"..variables[i])
		end


		local history_values
		local t_timeseries ={}

		local tstart = inmation.gettime(t_start_backcalc,  "%Y.%m.%d %H:%M:%S") 
		local tend   = inmation.gettime(t_end_backcalc,  "%Y.%m.%d %H:%M:%S") 
		local ts     = sampletime*60*1000 -- sampletime minutes in miliseconds

		local nperiods = math.ceil((tend-tstart)/ts)

		history_values = inmation.gethistory(variables_path, tstart, tend, nperiods, {"AGG_TYPE_INTERPOLATIVE"})
	
		for row =1, nperiods do
			for var = 1,#variables do
				if variables[var] ~= nil and history_values[var] ~= nil and history_values[var][row] ~= nil then
					inmation.setvalue(cwd.."/_Inputs/"..variables[var],history_values[var][row].V,history_values[var][row].Q,history_values[var][row].T)
				end
			end
		end

  -- clear all buffers before the model returns to normal online operation (so no old data in buffers will influence filtered values)
    for i,v in pairs(t) do
      inmation.tear(cwd.."/_Intermediates/"..v.alias,"RawBuffer")
      inmation.tear(cwd.."/_Intermediates/"..v.alias,"AvgBuffer")
    end

		inmation.enableobject (cwd.."/_Inputs/_read_inputs")

	end

	local function dowork()
	end

	local function main()

		-- this is required to use the script environment
		-- column call 
		env:entry()

		env:ensure(true,true,false)
		
		if 1 == env.calls then
			init()
		else 
			dowork()	
		end
		
		return env:exit() .. " ms"
	end

	return main

end

setUp.create_KPIlimit_holder = function(cwd,KPI_tab,lims, to_folder)
  -- this function creates Holder Objects for all Limits (High,highhigh,low, etc.) defined for a KPI
  -- this is needed to plot these limits into a VKPI Trend
  local objLib = require 'inmation.Objects'
  
  if not to_folder then
    to_folder = "/_Calculations"
  end
  
  local possible_lims = {"lowlowlow","lowlow","low","target","high","highhigh","highhighhigh"}
  if type(lims) == "table" then
    possible_lims = lims
  end
  local default_lims = {lowlowlow = 0,lowlow = 10,low = 0,target = 50,high = 80,highhigh = 90,highhighhigh = 100}
  
  for i,val in pairs(KPI_tab) do
    
    --create a Folder Holding all Limits for each KPI
    local folder_path, _ = objLib.ensureFolder(cwd..to_folder,val.objname.."Limits")
    
    for j,lim in pairs(possible_lims) do
      local cur_lim = default_lims[lim]
      if type(val[lim]) == "number" then
          cur_lim = val[lim]
      end
        local h_path, holder = objLib.ensureHolder(folder_path,val.objname..lim,'',cur_lim,nil,true,nil,nil,nil,nil,true)
        holder.ArchiveOptions.PersistencyMode = 3
        holder:commit()
      
    end
  end
end
    
setUp.alarming = function(iopath,kpipath,window,threshhold)
-- this function checks if the value of a KPI is exceeding its limits multiple times in a given window
-- window defines how many of the last values are checked, threshhold defines how many exceeded values should lead to alarming e.g. 8(threshhold) out of last 10(window) values high -> alarm!
-- this function returns 3,2,1 for HHH,HH and H alarm, -3,-2,-1 for LLL,LL,L alarm
	
	local obj = inmation.obj(iopath)
	local values = inmation.peek(obj,"AlarmingBuffer") -- look into buffer
	if #values == 0 then -- if the buffer is empty, it is not existing yet -> create it
		inmation.buffer(obj,"AlarmingBuffer",".ItemValue", 24*60*60*1000, window)
		return 0
	end
	
	local kpi = inmation.obj(kpipath) -- get the KPI object, so the Limits are accessable
	local Hcount, HHcount, HHHcount = 0,0,0
	local Lcount, LLcount, LLLcount = 0,0,0
	
	for i,val in pairs(values) do -- check every stored value, if its HHH,HH, etc. 
		
		if kpi.KpiLimits.KpiHHH ~= nil then
			if val > kpi.KpiLimits.KpiHHH then
				HHHcount = HHHcount +1
			end
		end
		if kpi.KpiLimits.KpiHH ~= nil then
			if val > kpi.KpiLimits.KpiHH then
				HHcount = HHcount +1
			end
		end
		if kpi.KpiLimits.KpiH ~= nil then
			if val > kpi.KpiLimits.KpiH then
				Hcount = Hcount +1
			end
		end
		if kpi.KpiLimits.KpiLLL ~= nil then
			if val < kpi.KpiLimits.KpiLLL then
				LLLcount = LLLcount +1
			end
		end	
		if kpi.KpiLimits.KpiLL ~= nil then
			if val < kpi.KpiLimits.KpiLL then
				LLcount = LLcount +1
			end
		end
		if kpi.KpiLimits.KpiL ~= nil then
			if val < kpi.KpiLimits.KpiL then
				Lcount = Lcount +1
			end
		end
	end
	
	if HHHcount >= threshhold then -- check the number of limit exceedings and return a number representing the alarm
		return 3
	end
	if HHcount  >= threshhold then
		return 2
	end
	if Hcount  >= threshhold then
		return 1
	end
  if LLLcount >= threshhold then
		return -3
  end
  if LLcount >= threshhold then
		return -2
	end
	if Lcount  >= threshhold then
		return -1
	end
  
	return 0 -- if no number of limit exceedings was to big, just return 0 -> no alarm
	
end

setUp.createKPI = function(kpistruct,props)
  -- this convenience function ensures a path and creates a kpi in the KPI model
  -- should only be used for non repeating special use cases. For templates a fully automated KPI generation should be developed.
  -- return: the path to the group folder. The path can be used to create additional KPIs and Trends at the same location (use modLib)
    
    local modLib = require "inmation.ObjectModelBASF"
    
    --ensure site
    local properties = { 
      ObjectName = kpistruct.site,
      ["KPIGroupSettings.DefaultGroupSettings.DefaultTab"] = 2,
    }
    local siteobj = modLib.upsertObject(kpistruct.startpath, "MODEL_CLASS_SITE", properties)

    --ensure a compound
    local properties = { 
      ObjectName = kpistruct.compound,
      ["KPIGroupSettings.DefaultGroupSettings.DefaultTab"] = 2,
    }
    local compoundobj = modLib.upsertObject(siteobj:path(), "MODEL_CLASS_PLANTCOMPOUND", properties)

    --ensure a plant
    local properties = { 
      ObjectName = kpistruct.plant, --e.g. Steamcracker 1
      ["KPIGroupSettings.DefaultGroupSettings.DefaultTab"] = 2,
    }
    local plantobj = modLib.upsertObject(compoundobj:path(), "MODEL_CLASS_PLANT", properties)


    --ensure a group folder
    local properties = { 
      ObjectName = kpistruct.equipment,
      ["KPIGroupSettings.DefaultGroupSettings.DefaultTab"] = 2,
    }
    local kpigroupobj = modLib.upsertObject(plantobj:path(), "MODEL_CLASS_KPIGROUP", properties)


-- create the KPI object at the given path 
modLib.upsertObject(kpigroupobj:path(), "MODEL_CLASS_GENKPI", props)

return kpigroupobj:path()
end


return setUp